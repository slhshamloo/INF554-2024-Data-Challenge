{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import fasttext\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = fasttext.load_model(\"data/fasttext_model.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(tweet, embedding_model):\n",
    "    tweet = preprocess_tweet(tweet)\n",
    "    words = tweet.split()\n",
    "    word_vectors = [embedding_model[word]\n",
    "                    for word in words if word in embedding_model]\n",
    "    # If no words in the tweet are in the vocabulary, return a zero vector\n",
    "    if not word_vectors:\n",
    "        return np.zeros(embedding_model.get_dimension())\n",
    "    return np.array(word_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, df, embedding_model):\n",
    "        self.df = df\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embeddings = df[\"Tweet\"].apply(\n",
    "            lambda tweet: get_embedding(tweet, embedding_model)).values\n",
    "        self.labels = df[\"EventType\"].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.embeddings[idx]),\n",
    "                torch.tensor(self.labels[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        df = pd.read_csv(os.path.join(folder, filename))\n",
    "        df.drop(columns=[\"MatchID\", \"PeriodID\", \"Timestamp\"],\n",
    "                inplace=True)\n",
    "        df.drop_duplicates(subset=\"Tweet\", inplace=True)\n",
    "        df[\"Tweet\"] = df[\"Tweet\"].apply(preprocess_tweet)\n",
    "        data.append(df)\n",
    "    return pd.concat(data)\n",
    "\n",
    "all_data = load_data(\"data/train_tweets/\")\n",
    "train_df, eval_df = train_test_split(all_data, test_size=0.2)\n",
    "\n",
    "train_dataset = TweetDataset(train_df, embedding_model)\n",
    "eval_dataset = TweetDataset(eval_df, embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad and Collate the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = max(len(embedding) for embedding, _ in train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    embeddings, labels = zip(*batch)\n",
    "    padded_embeddings = [\n",
    "        torch.cat((embedding, torch.zeros(max_len - len(embedding),\n",
    "            embedding.shape[1]))) if embedding.dim() > 1\n",
    "        else torch.cat((embedding.unsqueeze(0),\n",
    "                        torch.zeros(max_len - 1, len(embedding))))\n",
    "        for embedding in embeddings]\n",
    "    return (torch.stack(padded_embeddings).float(),\n",
    "            torch.stack(labels).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=pad_collate)\n",
    "eval_loader = DataLoader(eval_dataset, batch_size=32, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetClassifier(nn.Module):\n",
    "    def __init__(self, embed_dim, num_heads):\n",
    "        super(TweetClassifier, self).__init__()\n",
    "        self.multihead_attn = nn.MultiheadAttention(embed_dim, num_heads)\n",
    "        self.fc = nn.Linear(embed_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_output, _ = self.multihead_attn(x, x, x)\n",
    "        attn_output = attn_output.mean(dim=1)\n",
    "        out = self.fc(attn_output)\n",
    "        return self.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TweetClassifier(embedding_model.get_dimension(), 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.6629794880949829, Eval Loss: 0.6612436269283453\n",
      "Epoch 2/10, Train Loss: 0.6624214491535848, Eval Loss: 0.662690996077038\n",
      "Epoch 3/10, Train Loss: 0.6618990440690388, Eval Loss: 0.6619065216262247\n",
      "Epoch 4/10, Train Loss: 0.6619244266121287, Eval Loss: 0.6614277009279982\n",
      "Epoch 5/10, Train Loss: 0.6620126524577056, Eval Loss: 0.6622039313732904\n",
      "Epoch 6/10, Train Loss: 0.6615502313052863, Eval Loss: 0.6623980000123147\n",
      "Epoch 7/10, Train Loss: 0.6617466436981575, Eval Loss: 0.6611113632739634\n",
      "Epoch 8/10, Train Loss: 0.6612460567713732, Eval Loss: 0.6608686968832779\n",
      "Epoch 9/10, Train Loss: 0.6617135113695879, Eval Loss: 0.6613994423550141\n",
      "Epoch 10/10, Train Loss: 0.6615982409600434, Eval Loss: 0.6622519856007221\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available()\n",
    "                      else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, eval_loader,\n",
    "                criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "                embeddings, labels = batch\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(embeddings).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                train_loss += loss.item()\n",
    "\n",
    "        eval_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in eval_loader:\n",
    "                embeddings, labels = batch\n",
    "                embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "                outputs = model(embeddings).squeeze()\n",
    "                loss = criterion(outputs, labels)\n",
    "                eval_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "              f\"Train Loss: {train_loss/len(train_loader)}, \"\n",
    "              f\"Eval Loss: {eval_loss/len(eval_loader)}\")\n",
    "\n",
    "train_model(model, train_loader, eval_loader, criterion, optimizer)\n",
    "torch.save(model.state_dict(),\n",
    "           f\"data/fasttext_attention_{embedding_model.get_dimension()}.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.5638585168925235\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, eval_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in eval_loader:\n",
    "            embeddings, labels = batch\n",
    "            embeddings, labels = embeddings.to(device), labels.to(device)\n",
    "            outputs = model(embeddings).squeeze()\n",
    "            preds = (outputs > 0.5).float()\n",
    "            all_preds.extend(list(preds.cpu()))\n",
    "            all_labels.extend(list(labels.cpu()))\n",
    "\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    print(f\"Validation Accuracy: {accuracy}\")\n",
    "\n",
    "evaluate_model(model, eval_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TweetClassifier(\n",
       "  (multihead_attn): MultiheadAttention(\n",
       "    (out_proj): NonDynamicallyQuantizableLinear(in_features=200, out_features=200, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=200, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = fasttext.load_model(\"data/fasttext_model.bin\")\n",
    "model = TweetClassifier(embedding_model.get_dimension(), 8)\n",
    "model.load_state_dict(torch.load(\n",
    "    f\"data/fasttext_attention_{embedding_model.get_dimension()}.pt\",\n",
    "    weights_only=True))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, df, embedding_model):\n",
    "        self.df = df\n",
    "        self.embedding_model = embedding_model\n",
    "        self.embeddings = df[\"Tweet\"].apply(\n",
    "            lambda tweet: get_embedding(tweet, embedding_model)).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.embeddings[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    data = []\n",
    "    for filename in os.listdir(folder):\n",
    "        df = pd.read_csv(os.path.join(folder, filename))\n",
    "        df.drop(columns=[\"MatchID\", \"PeriodID\", \"Timestamp\"],\n",
    "                inplace=True)\n",
    "        df.drop_duplicates(subset=\"Tweet\", inplace=True)\n",
    "        df[\"Tweet\"] = df[\"Tweet\"].apply(preprocess_tweet)\n",
    "        data.append(df)\n",
    "    return pd.concat(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = load_data(\"data/train_tweets/\")\n",
    "train_dataset = TestDataset(train_df, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(embeddings):\n",
    "    padded_embeddings = [\n",
    "        torch.cat((embedding, torch.zeros(max_len - len(embedding),\n",
    "            embedding.shape[1]))) if embedding.dim() > 1\n",
    "        else torch.cat((embedding.unsqueeze(0),\n",
    "                        torch.zeros(max_len - 1, len(embedding))))\n",
    "        for embedding in embeddings]\n",
    "    return torch.stack(padded_embeddings).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preds(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for embeddings in test_loader:\n",
    "            preds = model(embeddings).squeeze()\n",
    "            if preds.dim() != 0:\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "            else:\n",
    "                all_preds.extend([0.0])\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"Confidence\"] = get_preds(model, train_loader)\n",
    "train_df.drop(columns=[\"Tweet\"], inplace=False).to_csv(\n",
    "    \"data/fasttext_attention_train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = load_data(\"data/eval_tweets/\")\n",
    "test_dataset = TestDataset(test_df, embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"Confidence\"] = get_preds(model, test_loader)\n",
    "test_df.drop(columns=[\"Tweet\"], inplace=False).to_csv(\n",
    "    \"data/fasttext_attention_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
