{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction based on the frequencies of some words\n",
    "We'll analyse the frequency of 17 chosen words in tweets : 'win', 'lose', 'draw', 'goal', 'red', 'yellow', 'penalty', 'foul', 'offfside', 'corner', 'free', 'kick', 'score', 'assist', 'pass', 'tackle'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing tweets\n",
    "I used a similar preprocessing that in the example of kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Lowercasing\n",
    "    text = text.lower()\n",
    "    # Remove punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Remove numbers\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    # Tokenization\n",
    "    words = text.split()\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "\n",
    "# Preprocess the train tweets\n",
    "\n",
    "li = []\n",
    "for filename in os.listdir(\"train_tweets\"):\n",
    "    print(\"File :\", filename)\n",
    "    df = pd.read_csv(\"train_tweets/\" + filename)\n",
    "    df['Tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "    li.append(df)\n",
    "\n",
    "df = pd.concat(li, ignore_index=True)\n",
    "\n",
    "os.mkdir(\"train_tweets_preprocessed\")\n",
    "df.to_csv(\"train_tweets_preprocessed/all_matches_preprocessed.csv\", index=False)\n",
    "\n",
    "# Preprocess the eval tweets\n",
    "\n",
    "li = []\n",
    "for filename in os.listdir(\"eval_tweets\"):\n",
    "    print(\"File :\", filename)\n",
    "    df = pd.read_csv(\"eval_tweets/\" + filename)\n",
    "    df['Tweet'] = df['Tweet'].apply(preprocess_text)\n",
    "    li.append(df)\n",
    "\n",
    "df = pd.concat(li, ignore_index=True)\n",
    "\n",
    "os.mkdir(\"eval_tweets_preprocessed\")\n",
    "df.to_csv(\"eval_tweets_preprocessed/all_matches_preprocessed.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the frequencies of our chosen words\n",
    "We compute the frequency : tweets containing the word / total tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words to search in tweets\n",
    "words = ['win', 'lose', 'draw', 'goal', 'red', 'yellow', 'penalty', 'foul', 'offfside', 'corner', 'free', 'kick', 'score', 'assist', 'pass', 'tackle']\n",
    "\n",
    "\n",
    "#Compute for train tweets\n",
    "\n",
    "df = pd.read_csv(\"train_tweets_preprocessed/all_matches_preprocessed.csv\")\n",
    "\n",
    "for word in words:\n",
    "    # Count the occurence of the word in each tweet\n",
    "    df['is_'+word+'_in_tweet'] = df['Tweet'].apply(lambda x: x.split().count(word))\n",
    "\n",
    "#Create a columns with only ones => To count the number of tweets\n",
    "df['tweet_count'] = 1\n",
    "\n",
    "# Sum the number of tweets where the word is present and groupd by ID\n",
    "specify_groupby = {'ID': 'first', 'MatchID': 'first', 'EventType': 'first', 'tweet_count': 'sum'}\n",
    "for word in words:\n",
    "    specify_groupby['is_'+word+'_in_tweet'] = 'sum'\n",
    "df_grouped_period = df.groupby('ID').agg(specify_groupby)\n",
    "\n",
    "#In the new DataFrame, the column 'is_word_in_tweet' contains the number of tweets where the word is present\n",
    "#We add a column that is the division of the number of tweets where the word is present by the total number of tweets\n",
    "\n",
    "for word in words:\n",
    "    df_grouped_period['tweet_freq_with_'+word+'_in'] = df_grouped_period['is_'+word+'_in_tweet'] / df_grouped_period['tweet_count']\n",
    "\n",
    "df_grouped_period.to_csv(\"train_tweets_preprocessed/all_frequencies_by_period.csv\", index=False)\n",
    "\n",
    "\n",
    "#Compute for eval tweets\n",
    "\n",
    "df = pd.read_csv(\"eval_tweets_preprocessed/all_matches_preprocessed.csv\")\n",
    "\n",
    "for word in words:\n",
    "    df['is_'+word+'_in_tweet'] = df['Tweet'].apply(lambda x: word in x)\n",
    "\n",
    "df['tweet_count'] = 1\n",
    "\n",
    "specify_groupby = {'ID': 'first', 'MatchID': 'first', 'tweet_count': 'sum'}\n",
    "for word in words:\n",
    "    specify_groupby['is_'+word+'_in_tweet'] = 'sum'\n",
    "df_grouped_period = df.groupby('ID').agg(specify_groupby)\n",
    "\n",
    "for word in words:\n",
    "    df_grouped_period['tweet_freq_with_'+word+'_in'] = df_grouped_period['is_'+word+'_in_tweet'] / df_grouped_period['tweet_count']\n",
    "\n",
    "df_grouped_period.to_csv(\"eval_tweets_preprocessed/all_frequencies_by_period.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try prediction on frequencies\n",
    "Change the max depth of the tree as you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6624448642793095\n"
     ]
    }
   ],
   "source": [
    "# Set the training columns\n",
    "words = ['win', 'lose', 'draw', 'goal', 'red', 'yellow', 'penalty', 'foul', 'offfside', 'corner', 'free', 'kick', 'score', 'assist', 'pass', 'tackle']\n",
    "\n",
    "train_columns = ['tweet_freq_with_'+word+'_in' for word in words]\n",
    "\n",
    "tree_depth = 4 # CAN BE CHANGED AS THE USER WANTS\n",
    "\n",
    "df = pd.read_csv('train_tweets_preprocessed/all_frequencies_by_period.csv')\n",
    "\n",
    "# Obtains the cross-validation accuracy\n",
    "\n",
    "match_ids = df['MatchID'].unique()\n",
    "accuracies = []\n",
    "\n",
    "for match in match_ids:\n",
    "    df_train = df[df['MatchID'] != match].copy()    \n",
    "    df_eval = df[df['MatchID'] == match].copy()\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=tree_depth)\n",
    "    decision_tree.fit(df_train[train_columns].values, df_train['EventType'].values)\n",
    "\n",
    "    df_eval['Prediction'] = decision_tree.predict(df_eval[train_columns].values)\n",
    "\n",
    "    correct_predictions = (df_eval['Prediction'] == df_eval['EventType']).sum()\n",
    "    total_predictions = len(df_eval)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    #print(f\"Correct predictions: {correct_predictions}, Total predictions: {total_predictions} => Accuracy: {accuracy}\")\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f\"Mean accuracy: {np.mean(accuracies)}\")\n",
    "\n",
    "#Train the model on the full training set and predict on the eval set\n",
    "df_train = pd.read_csv('train_tweets_preprocessed/all_frequencies_by_period.csv')\n",
    "df_eval = pd.read_csv('eval_tweets_preprocessed/all_frequencies_by_period.csv')\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(max_depth=tree_depth)\n",
    "decision_tree.fit(df_train[train_columns], df_train['EventType'])\n",
    "\n",
    "df_eval['EventType'] = decision_tree.predict(df_eval[train_columns])\n",
    "\n",
    "df_predicted = df_eval[['ID', 'EventType']].copy()\n",
    "\n",
    "os.makedirs(\"eval_tweets_prediction\", exist_ok=True)\n",
    "df_predicted.to_csv(\"eval_tweets_prediction/predictions_with_word_count_(depth=\"+str(tree_depth)+\").csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing word frequency per match to normalize frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Words used for training\n",
    "words = ['win', 'lose', 'draw', 'goal', 'red', 'yellow', 'penalty', 'foul', 'offfside', 'corner', 'free', 'kick','score', 'assist', 'pass', 'tackle']\n",
    "\n",
    "#Compute for train tweets\n",
    "df = pd.read_csv(\"train_tweets_preprocessed/all_frequencies_by_period.csv\")\n",
    "\n",
    "#Sum the number of tweets where the word is present and groupd by MatchID\n",
    "specify_groupby = {'MatchID': 'first', 'tweet_count': 'sum'}\n",
    "for word in words:\n",
    "    specify_groupby['is_'+word+'_in_tweet'] = 'sum'\n",
    "df_grouped_match = df.groupby('MatchID').agg(specify_groupby)\n",
    "\n",
    "#Divide by the total number of tweets to obtain the frequency of each word per match\n",
    "for word in words:\n",
    "    df_grouped_match['tweet_freq_with_'+word+'_in'] = df_grouped_match['is_'+word+'_in_tweet'] / df_grouped_match['tweet_count']\n",
    "\n",
    "df_grouped_match.to_csv(\"train_tweets_preprocessed/all_frequencies_by_match.csv\", index=False)\n",
    "\n",
    "\n",
    "#Compute for eval tweets\n",
    "df = pd.read_csv(\"eval_tweets_preprocessed/all_frequencies_by_period.csv\")\n",
    "\n",
    "specify_groupby = {'MatchID': 'first', 'tweet_count': 'sum'}\n",
    "for word in words:\n",
    "    specify_groupby['is_'+word+'_in_tweet'] = 'sum'\n",
    "df_grouped_match = df.groupby('MatchID').agg(specify_groupby)\n",
    "\n",
    "for word in words:\n",
    "    df_grouped_match['tweet_freq_with_'+word+'_in'] = df_grouped_match['is_'+word+'_in_tweet'] / df_grouped_match['tweet_count']\n",
    "\n",
    "df_grouped_match.to_csv(\"eval_tweets_preprocessed/all_frequencies_by_match.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardize frequencies with previously computed match frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word used for training\n",
    "words = ['win', 'lose', 'draw', 'goal', 'red', 'yellow', 'penalty', 'foul', 'offfside', 'corner', 'free', 'kick', 'score', 'assist', 'pass', 'tackle']\n",
    "\n",
    "# Function to compute the ratio between the previous frequency and the frequency of the word in the match\n",
    "def freq_to_freq_ratio(value, word,  matchID):\n",
    "    if value == 0:\n",
    "        return 0\n",
    "    return value / df_match.loc[df_match['MatchID'] == matchID, 'tweet_freq_with_'+word+'_in'].iloc[0] \n",
    "\n",
    "\n",
    "#Compute for train tweets\n",
    "df_period = pd.read_csv(\"train_tweets_preprocessed/all_frequencies_by_period.csv\")\n",
    "df_match = pd.read_csv(\"train_tweets_preprocessed/all_frequencies_by_match.csv\")\n",
    "\n",
    "for word in words:\n",
    "    df_period['tweet_freq_ratio_with_'+word+'_in'] = df_period.apply(lambda x: freq_to_freq_ratio(x['tweet_freq_with_'+word+'_in'], word, x['MatchID']), axis=1)\n",
    "\n",
    "df_period.to_csv(\"train_tweets_preprocessed/all_frequencies_by_period_with_ratio.csv\", index=False)\n",
    "\n",
    "#Compute for eval tweets\n",
    "df_period = pd.read_csv(\"eval_tweets_preprocessed/all_frequencies_by_period.csv\")\n",
    "df_match = pd.read_csv(\"eval_tweets_preprocessed/all_frequencies_by_match.csv\")\n",
    "\n",
    "for word in words:\n",
    "    df_period['tweet_freq_ratio_with_'+word+'_in'] = df_period.apply(lambda x: freq_to_freq_ratio(x['tweet_freq_with_'+word+'_in'], word, x['MatchID']), axis=1)\n",
    "\n",
    "df_period.to_csv(\"eval_tweets_preprocessed/all_frequencies_by_period_with_ratio.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try prediction on standardized frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy: 0.6316739003954741\n"
     ]
    }
   ],
   "source": [
    "# Set the training columns\n",
    "words = ['win', 'lose', 'draw', 'goal', 'red', 'yellow', 'penalty', 'foul', 'offfside', 'corner', 'free', 'kick', 'score', 'assist', 'pass', 'tackle']\n",
    "\n",
    "train_columns = ['tweet_freq_ratio_with_'+word+'_in' for word in words]\n",
    "\n",
    "tree_depth = 4\n",
    "\n",
    "df = pd.read_csv('train_tweets_preprocessed/all_frequencies_by_period_with_ratio.csv')\n",
    "\n",
    "# Obtains the cross-validation accuracy\n",
    "match_ids = df_train['MatchID'].unique()\n",
    "accuracies = []\n",
    "\n",
    "for match in match_ids:\n",
    "    df_train = df[df['MatchID'] != match].copy()    \n",
    "    df_eval = df[df['MatchID'] == match].copy()\n",
    "\n",
    "    decision_tree = DecisionTreeClassifier(max_depth=tree_depth)\n",
    "    decision_tree.fit(df_train[train_columns].values, df_train['EventType'].values)\n",
    "\n",
    "    df_eval['Prediction'] = decision_tree.predict(df_eval[train_columns].values)\n",
    "\n",
    "    correct_predictions = (df_eval['Prediction'] == df_eval['EventType']).sum()\n",
    "    total_predictions = len(df_eval)\n",
    "    accuracy = correct_predictions / total_predictions\n",
    "    #print(f\"Correct predictions: {correct_predictions}, Total predictions: {total_predictions} => Accuracy: {accuracy}\")\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "print(f\"Mean accuracy: {np.mean(accuracies)}\")\n",
    "\n",
    "#Train the model on the full training set and predict on the eval set\n",
    "df_train = pd.read_csv('train_tweets_preprocessed/all_frequencies_by_period_with_ratio.csv')\n",
    "df_eval = pd.read_csv('eval_tweets_preprocessed/all_frequencies_by_period_with_ratio.csv')\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(max_depth=tree_depth)\n",
    "decision_tree.fit(df_train[train_columns], df_train['EventType'])\n",
    "\n",
    "df_eval['Prediction'] = decision_tree.predict(df_eval[train_columns])\n",
    "\n",
    "df_predicted = df_eval[['ID', 'Prediction']].copy()\n",
    "\n",
    "os.makedirs(\"eval_tweets_prediction\", exist_ok=True)\n",
    "df_predicted.to_csv(\"eval_tweets_prediction/predictions_with_word_count_normalized_(depth=\"+str(tree_depth)+\").csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
